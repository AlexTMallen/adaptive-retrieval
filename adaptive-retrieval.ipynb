{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using adaptive retrieval on the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "\n",
    "seed = 633\n",
    "np.random.seed(seed)\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the results of parametric and nonparametric-augmented systems \n",
    "# and compute how well adaptive retrieval would perform\n",
    "do_plot = False\n",
    "n_boot = 100\n",
    "parametric_path = \"\"  # ADD PATH TO VANILLA RESULTS\n",
    "nonparametric_path = \"\"  # ADD PATH TO RETRIEVAL-AUGMENTED RESULTS\n",
    "def clean(df):\n",
    "    return df[~df[\"s_pop\"].isna() & (df[\"s_pop\"] >= 0)]\n",
    "sample = clean(pd.read_csv(parametric_path))\n",
    "sample_ret = clean(pd.read_csv(nonparametric_path))\n",
    "sample = sample.sort_values(\"question\").reset_index(drop=True)\n",
    "sample_ret = sample_ret.sort_values(\"question\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop adaptive: 1.0\n",
      "prop retrieval: 0.7981889543033361\n",
      "parametric knowledge only: 0.17163442668909443\n",
      "retrieval augmented accuracy: 0.2537706756377908\n",
      "hybrid accuracy: 0.2706980656013457 pm 0.000232407510793975\n",
      "hybrid accuracy on train: 0.2719317757009346\n",
      "overall accuracy gain: 0.016927389963554862\n",
      "overall accuracy: 0.2706980656013457\n"
     ]
    }
   ],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "props = sample.prop.unique()\n",
    "\n",
    "test_ret_accs_all = []\n",
    "test_param_accs_all = []\n",
    "test_hybrid_accs_all = []\n",
    "test_count_rets = []\n",
    "test_count_params = []\n",
    "train_hybrid_accs_all = []\n",
    "\n",
    "for boot in range(1 if do_plot else n_boot):\n",
    "    split_proportion = 0.75\n",
    "    split_mask = [\"train\"] * round(len(sample) * split_proportion) + [\"test\"] * round(len(sample) * (1 - split_proportion))\n",
    "    np.random.shuffle(split_mask)\n",
    "    sample[\"split\"] = split_mask\n",
    "    sample_ret[\"split\"] = split_mask\n",
    "\n",
    "    test_ret_accs = []\n",
    "    test_param_accs = []\n",
    "    test_hybrid_accs = []\n",
    "    train_hybrid_accs = []\n",
    "    test_count_rets.append(0)\n",
    "    test_count_params.append(0)\n",
    "    test_sizes = []\n",
    "    train_sizes = []\n",
    "    train_threshs = dict()\n",
    "    plot_title = \"\"\n",
    "    if do_plot:\n",
    "        plt.figure(dpi=200, figsize=(30, 30))\n",
    "    for i, prop in enumerate(props):\n",
    "\n",
    "        if do_plot:\n",
    "            plt.subplot(4, 4, i+1)\n",
    "        cluster_sample = sample[sample.prop == prop].copy()\n",
    "        cluster_sample_ret_with_pop = sample_ret[sample_ret.prop == prop].copy()\n",
    "\n",
    "        log_pop = np.log(cluster_sample[\"s_pop\"].values)\n",
    "        cluster_sample[\"log_pop\"] = log_pop\n",
    "        cluster_sample_ret_with_pop[\"log_pop\"] = log_pop\n",
    "        ser = log_pop\n",
    "        _, bin_edges = np.histogram(ser)\n",
    "\n",
    "        c = cluster_sample.is_correct.values\n",
    "        counts_c, _ = np.histogram(ser[c], bins=bin_edges)\n",
    "        counts_inc, _ = np.histogram(ser[~c], bins=bin_edges)\n",
    "        total = counts_c + counts_inc\n",
    "\n",
    "        c_ret = cluster_sample_ret_with_pop.is_correct.values\n",
    "        counts_c_ret, _ = np.histogram(ser[c_ret], bins=bin_edges)\n",
    "        counts_inc_ret, _ = np.histogram(ser[~c_ret], bins=bin_edges)\n",
    "        total_ret = counts_c_ret + counts_inc_ret\n",
    "\n",
    "        width = 0.4*(bin_edges[1] - bin_edges[0])\n",
    "        thresh_idx = np.argmax(list((sum(counts_c_ret[:i]) + sum(counts_c[i:])) / sum(total_ret) for i in range(len(total_ret) + 1)))\n",
    "\n",
    "        # plt.bar(bin_edges[:-1] - 0.5 * width, counts_c / total, width=width, alpha=0.9, label=\"parametric knowledge (vanilla)\", align='edge')\n",
    "        # plt.bar(bin_edges[:-1] + 0.5 * width, counts_c_ret / total_ret, width=width, alpha=0.9, label=\"retrieval augmented (BM25)\", align='edge')\n",
    "        # lo, hi = proportion_confint(counts_c, total, alpha=0.05, method='wilson')\n",
    "        # plt.errorbar(bin_edges[:-1], counts_c / total, yerr=[counts_c / total - lo, hi - counts_c / total], fmt='none', ecolor='black', elinewidth=1, capsize=2)\n",
    "        # lo, hi = proportion_confint(counts_c_ret, total_ret, alpha=0.05, method='wilson')\n",
    "        # plt.errorbar(bin_edges[:-1] + width, counts_c_ret / total_ret, yerr=[counts_c_ret / total_ret - lo, hi - counts_c_ret / total_ret], fmt='none', ecolor='black', elinewidth=1, capsize=2)\n",
    "        # # plt.errorbar(bin_edges[:-1], counts_c / total, , fmt='none', ecolor='black', capsize=2)\n",
    "        # # plt.errorbar(bin_edges[:-1], counts_c_ret / total_ret, yerr=wilson(counts_c_ret / total_ret, total_ret), fmt='none', ecolor='black', capsize=2)\n",
    "        # plt.axvline(x=bin_edges[thresh_idx] + 0.7 * (bin_edges[1] - bin_edges[0]), color='red', linestyle='--', label=\"threshold\")\n",
    "\n",
    "        param_acc = sum(counts_c) / sum(total)\n",
    "        ret_acc = sum(counts_c_ret) / sum(total_ret)\n",
    "        hybrid_acc = (sum(counts_c_ret[:thresh_idx]) + sum(counts_c[thresh_idx:])) / (sum(total_ret[:thresh_idx]) + sum(total[thresh_idx:]))\n",
    "        ret_acc_gain = hybrid_acc - ret_acc\n",
    "        param_acc_gain = hybrid_acc - param_acc\n",
    "        \n",
    "        # let the optimal threshold be the one that maximizes the hybrid accuracy\n",
    "        train_idxs = cluster_sample.split.values == \"train\"\n",
    "        test_idxs = cluster_sample.split.values == \"test\"\n",
    "        train_ser = ser[train_idxs]\n",
    "        test_ser = ser[test_idxs]\n",
    "        train_c = c[train_idxs]\n",
    "        test_c = c[test_idxs]\n",
    "        train_c_ret = c_ret[train_idxs]\n",
    "        test_c_ret = c_ret[test_idxs]\n",
    "        train_counts_c, _ = np.histogram(train_ser[train_c], bins=bin_edges)\n",
    "        train_counts_inc, _ = np.histogram(train_ser[~train_c], bins=bin_edges)\n",
    "        train_total = train_counts_c + train_counts_inc\n",
    "        train_counts_c_ret, _ = np.histogram(train_ser[train_c_ret], bins=bin_edges)\n",
    "        train_counts_inc_ret, _ = np.histogram(train_ser[~train_c_ret], bins=bin_edges)\n",
    "        train_total_ret = train_counts_c_ret + train_counts_inc_ret\n",
    "        test_counts_c, _ = np.histogram(test_ser[test_c], bins=bin_edges)\n",
    "        test_counts_inc, _ = np.histogram(test_ser[~test_c], bins=bin_edges)\n",
    "        test_total = test_counts_c + test_counts_inc\n",
    "        test_counts_c_ret, _ = np.histogram(test_ser[test_c_ret], bins=bin_edges)\n",
    "        test_counts_inc_ret, _ = np.histogram(test_ser[~test_c_ret], bins=bin_edges)\n",
    "        test_total_ret = test_counts_c_ret + test_counts_inc_ret\n",
    "        \n",
    "        # find the optimal threshold\n",
    "        train_thresh_idx = np.argmax(list((sum(train_counts_c_ret[:i]) + sum(train_counts_c[i:])) / (sum(train_total_ret[:i]) + sum(train_total[i:])) for i in range(len(train_total) + 1)))\n",
    "        train_thresh = bin_edges[train_thresh_idx] - 0.5 * (bin_edges[1] - bin_edges[0])\n",
    "        train_threshs[prop] = train_thresh\n",
    "\n",
    "        # calculate the accuracy on the test set\n",
    "        test_param_acc = sum(test_counts_c) / sum(test_total)\n",
    "        test_ret_acc = sum(test_counts_c_ret) / sum(test_total_ret)\n",
    "        test_hybrid_acc = (sum(test_counts_c_ret[:train_thresh_idx]) + sum(test_counts_c[train_thresh_idx:])) / (sum(test_total_ret[:train_thresh_idx]) + sum(test_total[train_thresh_idx:]))\n",
    "        test_sizes.append(sum(test_total))\n",
    "        test_count_rets[-1] += sum(test_total_ret[:train_thresh_idx])\n",
    "        test_count_params[-1] += sum(test_total[train_thresh_idx:])\n",
    "        test_ret_accs.append(test_ret_acc)\n",
    "        test_param_accs.append(test_param_acc)\n",
    "        test_hybrid_accs.append(test_hybrid_acc)\n",
    "        train_hybrid_accs.append((sum(train_counts_c_ret[:train_thresh_idx]) + sum(train_counts_c[train_thresh_idx:])) / (sum(train_total_ret[:train_thresh_idx]) + sum(train_total[train_thresh_idx:])))\n",
    "        train_sizes.append(sum(train_total))\n",
    "\n",
    "        if do_plot:\n",
    "            plt.bar(bin_edges[:-1] - 0.5 * width, test_counts_c / test_total, width=width, alpha=0.9, label=\"parametric knowledge (vanilla)\", align='edge', hatch='//')\n",
    "            plt.bar(bin_edges[:-1] + 0.5 * width, test_counts_c_ret / test_total_ret, width=width, alpha=0.9, label=\"retrieval augmented (BM25)\", align='edge', hatch='//')\n",
    "            lo, hi = proportion_confint(test_counts_c, test_total, alpha=0.05, method='wilson')\n",
    "            plt.errorbar(bin_edges[:-1], test_counts_c / test_total, yerr=[test_counts_c / test_total - lo, hi - test_counts_c / test_total], fmt='none', ecolor='black', elinewidth=1, capsize=2)\n",
    "            lo, hi = proportion_confint(test_counts_c_ret, test_total_ret, alpha=0.05, method='wilson')\n",
    "            plt.errorbar(bin_edges[:-1] + width, test_counts_c_ret / test_total_ret, yerr=[test_counts_c_ret / test_total_ret - lo, hi - test_counts_c_ret / test_total_ret], fmt='none', ecolor='black', elinewidth=1, capsize=2)\n",
    "            plt.axvline(x=bin_edges[train_thresh_idx] - 0.8 * width, color='red', linestyle='--', label=\"threshold\")\n",
    "\n",
    "            print(f\"Threshold for {prop}:\", train_thresh)\n",
    "            print(\"Parametric knowledge only:\", param_acc)\n",
    "            print(\"Retrieval augmented accuracy:\", ret_acc)\n",
    "            print(f\"New accuracy with thresh={thresh_idx}:\", hybrid_acc)\n",
    "            print()\n",
    "            plt.title(f\"{prop}\")\n",
    "            plt.ylim([0,1.01])\n",
    "    if do_plot:\n",
    "        plt.xlabel(\"log(s_pop)\")\n",
    "        plt.ylabel(\"proportion correct\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # take the weighted mean by test_size\n",
    "    test_ret_accs_all.append(np.average(test_ret_accs, weights=test_sizes))\n",
    "    test_param_accs_all.append(np.average(test_param_accs, weights=test_sizes))\n",
    "    test_hybrid_accs_all.append(np.average(test_hybrid_accs, weights=test_sizes))\n",
    "    train_hybrid_accs_all.append(np.average(train_hybrid_accs, weights=train_sizes))\n",
    "\n",
    "test_size = split_mask.count(\"test\")\n",
    "prop_adaptive = (np.mean(test_count_rets) + np.mean(test_count_params)) / test_size\n",
    "param_acc = np.mean(test_param_accs_all)\n",
    "ret_acc = np.mean(test_ret_accs_all)\n",
    "hybrid_acc = np.mean(test_hybrid_accs_all)\n",
    "train_hybrid_acc = np.mean(train_hybrid_accs_all)\n",
    "overall_hybrid_acc = np.mean(test_hybrid_accs_all) * prop_adaptive + max(np.mean(test_param_accs_all), np.mean(test_ret_accs_all)) * (1 - prop_adaptive)\n",
    "sem_test_hybrid_acc = 2 * np.std(test_hybrid_accs_all) / np.sqrt(test_size)\n",
    "print(\"prop adaptive:\", prop_adaptive)\n",
    "print(\"prop retrieval:\", np.mean(test_count_rets) / test_size)\n",
    "print(\"parametric knowledge only:\", param_acc)\n",
    "print(\"retrieval augmented accuracy:\", ret_acc)\n",
    "print(\"hybrid accuracy:\", hybrid_acc, \"pm\", sem_test_hybrid_acc)\n",
    "print(\"hybrid accuracy on train:\", train_hybrid_acc)\n",
    "print(\"overall accuracy gain:\", overall_hybrid_acc - max(param_acc, ret_acc))\n",
    "print(\"overall accuracy:\", overall_hybrid_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
